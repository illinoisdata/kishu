{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff189b3b-c1f4-43fe-90bd-3276db946aca",
   "metadata": {},
   "source": [
    "# Task 1: Data Analysis\n",
    "Please make sure you <span style=\"color: red\">run every cell</span> in the task. You <span style=\"color: red\">don't need to</span> read the detail of any code snippets we provided. \n",
    "\n",
    "You should **never** unfold the next part before the previous part is done.\n",
    "\n",
    "Today, you would like to build a model to predict the median housing price in California.\n",
    "\n",
    "Thankfully, your coworker has prepared a few options to help you build the model.\n",
    "\n",
    "**Once you see \"CHOOSE ONE\", copy, paste, and execute <span style=\"color: red\"> any one of the choices </span> in the cell below.**\n",
    "\n",
    "You are free to run other cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837dc10-2577-4e73-9a99-29ce4b4e12a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 0: Load Libraries and Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba1580-2237-49cf-9464-4ea723231fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from kishu.user_study import install_submit_cell_execution\n",
    "install_submit_cell_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726858-b53f-4dcc-81ab-0afbd32b2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"./housing_california.csv\")\n",
    "print(housing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339b7d5-6490-41a3-9734-948cc66a6c06",
   "metadata": {},
   "source": [
    "The median_house_value is the thing you need to predict using other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cba50-3582-417e-87cd-f88e4fe0c072",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb80792-6ea9-47d9-99a9-788daea62359",
   "metadata": {},
   "source": [
    "### Impute the missing values (CHOOSE ONE)\n",
    "\n",
    "Two choices to impute 207 missing values in the `total_bedrooms` column.\n",
    "\n",
    "1. **Choice 1**: Median Imputation. Simplicity is good for this dataset size.\n",
    "```python\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(housing.iloc[:,4:5])\n",
    "housing.iloc[:,4:5] = imputer.transform(housing.iloc[:,4:5])\n",
    "```\n",
    "2. **Choice 2**: kNN Unsupervised Learning Imputation. Median imputation can introduce bias; kNN imputer can provide a better representation.\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "housing_scaled = pd.DataFrame(scaler.fit_transform(housing), columns=housing.columns)\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "housing_imputed = pd.DataFrame(knn_imputer.fit_transform(housing_scaled), columns=housing.columns)\n",
    "housing_imputed = pd.DataFrame(scaler.inverse_transform(housing_imputed), columns=housing.columns)\n",
    "housing['total_bedrooms'] = housing_imputed['total_bedrooms']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e094add-e498-41fc-994a-ec9598b03f90",
   "metadata": {},
   "source": [
    "**Paste and run** the code of your choice **in the cell below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fed1f-9ff6-411e-a523-cf8300a7b0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22736b10-d7f6-4d96-9232-103905721681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure there is no missing value\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed26dcf-6844-47e6-819e-460470be7756",
   "metadata": {},
   "source": [
    "### Train test set split (CHOOSE ONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3617c2-4c85-4e25-af4a-2c677ace281c",
   "metadata": {},
   "source": [
    "How would you split the dataset into train and test sets?\n",
    "\n",
    "1. **Choice 1**: Random split to be fair.\n",
    "```python\n",
    "tr_data, te_data = train_test_split(housing, test_size=0.2, random_state=43)\n",
    "```\n",
    "2. **Choice 2**: Stratified split, given the correlation between columns.\n",
    "```python\n",
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)\n",
    "tr_data, te_data = train_test_split(housing, test_size=0.2, stratify=housing['income_cat'])\n",
    "housing = housing.drop('income_cat',axis=1)\n",
    "tr_data = tr_data.drop('income_cat',axis=1)\n",
    "te_data = te_data.drop('income_cat',axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85802714-ec1f-40cc-8acc-2f35d453ad36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a484a7-3bca-4fb1-b8d9-cbf06634a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure splitting is successful\n",
    "print(tr_data.shape, te_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9229e6-42d4-43ed-ad8f-2169a93b2797",
   "metadata": {},
   "source": [
    "### Divide the data into feature (X) and target (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a287e7-ba2a-4e2c-8aaf-309d94618fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training data\n",
    "X_train = tr_data.drop('median_house_value', axis=1)\n",
    "Y_train = tr_data['median_house_value']\n",
    "\n",
    "# For the testing data\n",
    "X_test = te_data.drop('median_house_value', axis=1)\n",
    "Y_test = te_data['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b5284-c0a1-4094-95b5-cd20c8d66ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the dataset is complete\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3b050-97c2-47fa-a695-baad158cda99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 2: Feature Engineering\n",
    "\n",
    "Several features (`total_rooms`, `total_bedrooms`, `longitude`, `latitude`) are highly correlated, let's simply drop some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf4c6d-1778-4048-ae91-3406f97ee401",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['total_bedrooms']\n",
    "del X_test['total_bedrooms']\n",
    "del X_train['longitude']\n",
    "del X_test['longitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3a885-5dd2-45d7-afeb-764609c0eb1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 3: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd9323-b703-4347-b65c-17eb17da7312",
   "metadata": {},
   "source": [
    "### Select the model to use (CHOOSE ONE)\n",
    "\n",
    "Let's try either of the two models.\n",
    "\n",
    "1. **Choice 1**: Linear regression\n",
    "```python\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train, Y_train)\n",
    "```\n",
    "2. **Choice 2**: Random Forest\n",
    "```python\n",
    "model = RandomForestRegressor(30)\n",
    "model.fit(X_train, Y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7a2d7-1b10-43dd-956f-75ff80a37d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9fff898-69f7-45ec-9fda-c4385a11ab28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616fab2-1ae1-42f6-a183-8f64c2a759f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model using RMSE\n",
    "Y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf740c-b161-453e-8969-7a152fee249d",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4664f-496e-468e-a77f-5b7214058812",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 5: Alternative Feature Engineering: <span style=\"color: red\">Please make sure to read every line of this part</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e9e74-5b20-47a3-bb4e-d3613c8bb141",
   "metadata": {},
   "source": [
    "Your coworker realized that `Part 2 Feature Engineering` should instead combine the correlated features into new features.\n",
    "\n",
    "**Use the following feature Engineering method instead of the one in Part 2, but  <span style=\"color: red\">keep all your other choices</span>. Then, Re-run the model training and evaluation (Part 3 and Part 4).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280c497-5b29-4cd1-b72a-9b2474a8aee5",
   "metadata": {},
   "source": [
    "### Code for New Feature Engineering Method\n",
    "**Note**:  <span style=\"color:red\">Because `X_train['longitude']` is already dropped, the following code will lead to bug if you execute it directly</span>. \n",
    "\n",
    "```python\n",
    "X_train['diag_coord'] = X_train['longitude'] + X_train['latitude']\n",
    "X_train['bedperroom'] = X_train['total_bedrooms'] / X_train['total_rooms']\n",
    "X_test['diag_coord'] = X_test['longitude'] + X_test['latitude']\n",
    "X_test['bedperroom'] = X_test['total_bedrooms'] / X_test['total_rooms']\n",
    "X_train = X_train.drop(['longitude', 'latitude', 'total_bedrooms', 'total_rooms'], axis=1)\n",
    "X_test = X_test.drop(['longitude', 'latitude', 'total_bedrooms', 'total_rooms'], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc13923-cb8e-42bf-89f8-e32818499463",
   "metadata": {},
   "source": [
    "### Please answer the following question here.\n",
    "\n",
    "Which feature engineering method has better accuracy? (please answer either `old way` or `new way` below)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4027ebf-5c6a-4b38-915e-1735de47a119",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f27c3592-873c-4565-a762-2d09b5f470a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358214e7-bd28-4673-a5e6-c286fc43a94f",
   "metadata": {},
   "source": [
    "Please export the models you trained by the first and second feature engineering methods respectively using the following code:\n",
    "1. For the first model\n",
    "   ```python\n",
    "   dump(model, 'drop_feature.joblib') \n",
    "   ```\n",
    "2. For the second model\n",
    "   ```python\n",
    "   dump(model, 'replace_feature.joblib')\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a755ca-6e9c-4ab2-8f79-d1ad877c089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c727027-6ad1-4b13-ac0d-346b8228999b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
