{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff189b3b-c1f4-43fe-90bd-3276db946aca",
   "metadata": {},
   "source": [
    "# Task 1: Data Analysis\n",
    "Please make sure you <span style=\"color: red\">run every cell</span> in the task. You <span style=\"color: red\">don't need to</span> read the detail of any code snippets we provided. \n",
    "\n",
    "You should **never** unfold the next part before the previous part is done.\n",
    "\n",
    "Today, you would like to build a model to predict the median housing price in California.\n",
    "\n",
    "Thankfully, your coworker has prepared a few options to help you build the model.\n",
    "\n",
    "**Once you see \"CHOOSE ONE\", copy, paste, and execute <span style=\"color: red\"> any one of the choices </span> in the cell below.**\n",
    "\n",
    "You are free to run other cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837dc10-2577-4e73-9a99-29ce4b4e12a9",
   "metadata": {},
   "source": [
    "## Part 0: Load Libraries and Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba1580-2237-49cf-9464-4ea723231fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from kishu.user_study import install_submit_cell_execution\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "install_submit_cell_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726858-b53f-4dcc-81ab-0afbd32b2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"./housing_california.csv\")\n",
    "print(housing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339b7d5-6490-41a3-9734-948cc66a6c06",
   "metadata": {},
   "source": [
    "The `median_house_value` is the thing you need to predict using other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cba50-3582-417e-87cd-f88e4fe0c072",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb80792-6ea9-47d9-99a9-788daea62359",
   "metadata": {},
   "source": [
    "### Impute the missing values (CHOOSE ONE)\n",
    "\n",
    "Two choices to impute 207 missing values in the `total_bedrooms` column.\n",
    "\n",
    "1. **Choice 1**: Median Imputation. Simplicity is good for this dataset size.\n",
    "```python\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(housing.iloc[:,4:5])\n",
    "housing.iloc[:,4:5] = imputer.transform(housing.iloc[:,4:5])\n",
    "```\n",
    "2. **Choice 2**: kNN Unsupervised Learning Imputation. Median imputation can introduce bias; kNN imputer can provide a better representation.\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "housing_scaled = pd.DataFrame(scaler.fit_transform(housing), columns=housing.columns)\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "housing_imputed = pd.DataFrame(knn_imputer.fit_transform(housing_scaled), columns=housing.columns)\n",
    "housing_imputed = pd.DataFrame(scaler.inverse_transform(housing_imputed), columns=housing.columns)\n",
    "housing['total_bedrooms'] = housing_imputed['total_bedrooms']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e094add-e498-41fc-994a-ec9598b03f90",
   "metadata": {},
   "source": [
    "**Paste and run** the code of your choice **in the cell below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fed1f-9ff6-411e-a523-cf8300a7b0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22736b10-d7f6-4d96-9232-103905721681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure there is no missing value\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3b050-97c2-47fa-a695-baad158cda99",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering\n",
    "\n",
    "Several features (`total_rooms`, `total_bedrooms`, `longitude`, `latitude`) are highly correlated, let's simply drop some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf4c6d-1778-4048-ae91-3406f97ee401",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.drop([\"total_bedrooms\"], axis=1, inplace=True)\n",
    "housing.drop([\"longitude\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3a885-5dd2-45d7-afeb-764609c0eb1a",
   "metadata": {},
   "source": [
    "## Part 3: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f781e-e015-4cfb-aa1e-f25b2cd4e656",
   "metadata": {},
   "source": [
    "### Train test set split (CHOOSE ONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b2346-eed9-452d-97ac-38a49821fd99",
   "metadata": {},
   "source": [
    "How would you split the dataset into train and test sets?\n",
    "\n",
    "1. **Choice 1**: Random split to be fair.\n",
    "```python\n",
    "tr_data, te_data = train_test_split(housing, test_size=0.2, random_state=43)\n",
    "```\n",
    "2. **Choice 2**: Stratified split, given the correlation between columns.\n",
    "```python\n",
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace=True)\n",
    "tr_data, te_data = train_test_split(housing, test_size=0.2, stratify=housing['income_cat'])\n",
    "housing = housing.drop('income_cat',axis=1)\n",
    "tr_data = tr_data.drop('income_cat',axis=1)\n",
    "te_data = te_data.drop('income_cat',axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85802714-ec1f-40cc-8acc-2f35d453ad36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a484a7-3bca-4fb1-b8d9-cbf06634a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure splitting is successful\n",
    "print(tr_data.shape, te_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a55c0f-c933-47c6-86e2-a9c6a189ce1e",
   "metadata": {},
   "source": [
    "### Divide the data into feature (X) and target (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a287e7-ba2a-4e2c-8aaf-309d94618fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training data\n",
    "X_train = tr_data.drop(\"median_house_value\", axis=1)\n",
    "Y_train = tr_data[\"median_house_value\"]\n",
    "\n",
    "# For the testing data\n",
    "X_test = te_data.drop(\"median_house_value\", axis=1)\n",
    "Y_test = te_data[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b5284-c0a1-4094-95b5-cd20c8d66ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the dataset is complete\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd9323-b703-4347-b65c-17eb17da7312",
   "metadata": {},
   "source": [
    "### Select the model to use (CHOOSE ONE)\n",
    "\n",
    "Let's try either of the two models.\n",
    "\n",
    "1. **Choice 1**: Linear regression\n",
    "```python\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train, Y_train)\n",
    "```\n",
    "2. **Choice 2**: Random Forest\n",
    "```python\n",
    "model = RandomForestRegressor(30)\n",
    "model.fit(X_train, Y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7a2d7-1b10-43dd-956f-75ff80a37d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9fff898-69f7-45ec-9fda-c4385a11ab28",
   "metadata": {},
   "source": [
    "## Part 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616fab2-1ae1-42f6-a183-8f64c2a759f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model using RMSE\n",
    "Y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf740c-b161-453e-8969-7a152fee249d",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4664f-496e-468e-a77f-5b7214058812",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 5: Alternative Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e9e74-5b20-47a3-bb4e-d3613c8bb141",
   "metadata": {},
   "source": [
    "Suppose you would like to explore a new approach. \n",
    "\n",
    "**Previously:** We tried deleting correlated features in Part 2.\n",
    "\n",
    "```python\n",
    "housing.drop([\"total_bedrooms\"], axis=1, inplace=True)\n",
    "housing.drop([\"longitude\"], axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "**Now:** Instead of deleting, Let's try a new way to combine correlated features into new features first, then delete them.\n",
    " \n",
    "```python\n",
    "housing['diag_coord'] = housing['longitude'] + housing['latitude']\n",
    "housing['bedperroom'] = housing['total_bedrooms'] / housing['total_rooms']\n",
    "housing.drop(['longitude', 'latitude'], axis=1, inplace=True)\n",
    "housing.drop(['total_bedrooms', 'total_rooms'], axis=1, inplace=True)\n",
    "```\n",
    "**Task**: Try the new feature engineering method instead of the previous one, retrain and re-evaluate the model of your previous choice based on the new method.\n",
    "\n",
    " <span style=\"color:red\">**Note**</span>: `housing['longitude']` is already dropped by the old method, so you cannot run the new feature engineering method directly without recovering the data in kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ff302-3b4b-4802-9e6c-d58f73cefb2d",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545fe13-d3eb-414e-aa6d-32a0f6ea63ef",
   "metadata": {},
   "source": [
    "Make sure you see the new RMSE before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c2b60-ea1e-4ec8-88fe-896def98888a",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc13923-cb8e-42bf-89f8-e32818499463",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2e9d0-4b01-48b6-b149-2da0ed8d0436",
   "metadata": {},
   "source": [
    "### Report result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa85f97-b19c-4fce-bb04-8f28411fdc99",
   "metadata": {},
   "source": [
    "**Task:** Please report the `rmse` for the old model and the new model.\n",
    "\n",
    "Answer in the <span style=\"color:red\">text file</span> opened for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c3592-873c-4565-a762-2d09b5f470a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd03743-03b7-4be5-9ab4-3faa71a84bb0",
   "metadata": {},
   "source": [
    "### Dump model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358214e7-bd28-4673-a5e6-c286fc43a94f",
   "metadata": {},
   "source": [
    "Let's export both models for later investigation.\n",
    "\n",
    "**Task**: Please export the models you trained based on the first and second feature engineering methods:\n",
    "\n",
    "The exported files' name should be `\"old_way.joblib\"` and `\"new_way.joblib\"` respectively. \n",
    "\n",
    "To dump a file, you can use the following code:\n",
    "   ```python\n",
    "   dump(model, \"old_way.joblib\") \n",
    "   ```\n",
    "and\n",
    "   ```python\n",
    "   dump(model, \"new_way.joblib\") \n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a755ca-6e9c-4ab2-8f79-d1ad877c089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c17a44d-7172-4103-a552-e6397e550ffe",
   "metadata": {},
   "source": [
    "You should be able to see `old_way.joblib` and `new_way.joblib` files at the left panel, which means the model is exported successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
