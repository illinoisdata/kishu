{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Get the data here: https://www.kaggle.com/datasets/ajayrana/hymenoptera-data\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "%load_ext ElasticNotebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<contextlib.ExitStack at 0x1288410d0>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/hymenoptera_data/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 19\u001B[0m\n\u001B[1;32m      3\u001B[0m data_transforms \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m: transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m      5\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mRandomResizedCrop(\u001B[38;5;241m224\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m     ]),\n\u001B[1;32m     16\u001B[0m }\n\u001B[1;32m     18\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/hymenoptera_data\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 19\u001B[0m image_datasets \u001B[38;5;241m=\u001B[39m {x: datasets\u001B[38;5;241m.\u001B[39mImageFolder(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, x),\n\u001B[1;32m     20\u001B[0m                                           data_transforms[x])\n\u001B[1;32m     21\u001B[0m                   \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n\u001B[1;32m     22\u001B[0m dataloaders \u001B[38;5;241m=\u001B[39m {x: torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(image_datasets[x], batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     23\u001B[0m                                              shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m     24\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n\u001B[1;32m     25\u001B[0m dataset_sizes \u001B[38;5;241m=\u001B[39m {x: \u001B[38;5;28mlen\u001B[39m(image_datasets[x]) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n",
      "Cell \u001B[0;32mIn [3], line 19\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      3\u001B[0m data_transforms \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m: transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m      5\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mRandomResizedCrop(\u001B[38;5;241m224\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m     ]),\n\u001B[1;32m     16\u001B[0m }\n\u001B[1;32m     18\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/hymenoptera_data\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 19\u001B[0m image_datasets \u001B[38;5;241m=\u001B[39m {x: \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mdata_transforms\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m                   \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n\u001B[1;32m     22\u001B[0m dataloaders \u001B[38;5;241m=\u001B[39m {x: torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(image_datasets[x], batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     23\u001B[0m                                              shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m     24\u001B[0m               \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n\u001B[1;32m     25\u001B[0m dataset_sizes \u001B[38;5;241m=\u001B[39m {x: \u001B[38;5;28mlen\u001B[39m(image_datasets[x]) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py:310\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    304\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    308\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m ):\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py:145\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    137\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    142\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    143\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[0;32m--> 145\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, class_to_idx, extensions, is_valid_file)\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py:219\u001B[0m, in \u001B[0;36mDatasetFolder.find_classes\u001B[0;34m(self, directory)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, directory: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001B[39;00m\n\u001B[1;32m    194\u001B[0m \n\u001B[1;32m    195\u001B[0m \u001B[38;5;124;03m        directory/\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 219\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torchvision/datasets/folder.py:41\u001B[0m, in \u001B[0;36mfind_classes\u001B[0;34m(directory)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(directory: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m    See :class:`DatasetFolder` for details.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m     classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(entry\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any class folder in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/hymenoptera_data/train'"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdevice\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab526115",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 15\u001B[0m\n\u001B[1;32m     11\u001B[0m     plt\u001B[38;5;241m.\u001B[39mpause(\u001B[38;5;241m0.001\u001B[39m)  \u001B[38;5;66;03m# pause a bit so that plots are updated\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Get a batch of training data\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m inputs, classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mdataloaders\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Make a grid from batch\u001B[39;00m\n\u001B[1;32m     18\u001B[0m out \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mmake_grid(inputs)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cc536c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01997c19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libilly/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/libilly/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [7], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Here the size of each output sample is set to 2.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\u001B[39;00m\n\u001B[1;32m      5\u001B[0m model_ft\u001B[38;5;241m.\u001B[39mfc \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(num_ftrs, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m model_ft \u001B[38;5;241m=\u001B[39m model_ft\u001B[38;5;241m.\u001B[39mto(\u001B[43mdevice\u001B[49m)\n\u001B[1;32m      9\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Observe that all parameters are being optimized\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36fc7f0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model_ft \u001B[38;5;241m=\u001B[39m train_model(model_ft, \u001B[43mcriterion\u001B[49m, optimizer_ft, exp_lr_scheduler,\n\u001B[1;32m      2\u001B[0m                        num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faffc37b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34356f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mvisualize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_ft\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [9], line 8\u001B[0m, in \u001B[0;36mvisualize_model\u001B[0;34m(model, num_images)\u001B[0m\n\u001B[1;32m      5\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (inputs, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mdataloaders\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m      9\u001B[0m         inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     10\u001B[0m         labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataloaders' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5340b02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [11], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m num_ftrs \u001B[38;5;241m=\u001B[39m model_conv\u001B[38;5;241m.\u001B[39mfc\u001B[38;5;241m.\u001B[39min_features\n\u001B[1;32m      7\u001B[0m model_conv\u001B[38;5;241m.\u001B[39mfc \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(num_ftrs, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m model_conv \u001B[38;5;241m=\u001B[39m model_conv\u001B[38;5;241m.\u001B[39mto(\u001B[43mdevice\u001B[49m)\n\u001B[1;32m     11\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Observe that only parameters of final layer are being optimized as\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# opposed to before.\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24112960",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model_conv \u001B[38;5;241m=\u001B[39m train_model(model_conv, \u001B[43mcriterion\u001B[49m, optimizer_conv,\n\u001B[1;32m      2\u001B[0m                          exp_lr_scheduler, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf79aad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mvisualize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_conv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mioff()\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "Cell \u001B[0;32mIn [9], line 8\u001B[0m, in \u001B[0;36mvisualize_model\u001B[0;34m(model, num_images)\u001B[0m\n\u001B[1;32m      5\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (inputs, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mdataloaders\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m      9\u001B[0m         inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     10\u001B[0m         labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataloaders' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ce1a8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a8a05ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/170498071 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a3fe40527454272b87effdcc301d2b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2fed09d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane cat   cat   dog  \n"
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4c8011",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9ae5981",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c84426",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.222\n",
      "[1,  4000] loss: 1.934\n",
      "[1,  6000] loss: 1.730\n",
      "[1,  8000] loss: 1.614\n",
      "[1, 10000] loss: 1.558\n",
      "[1, 12000] loss: 1.502\n",
      "[2,  2000] loss: 1.410\n",
      "[2,  4000] loss: 1.401\n",
      "[2,  6000] loss: 1.365\n",
      "[2,  8000] loss: 1.340\n",
      "[2, 10000] loss: 1.339\n",
      "[2, 12000] loss: 1.335\n",
      "[3,  2000] loss: 1.247\n",
      "[3,  4000] loss: 1.245\n",
      "[3,  6000] loss: 1.245\n",
      "[3,  8000] loss: 1.231\n",
      "[3, 10000] loss: 1.205\n",
      "[3, 12000] loss: 1.204\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 68720) is killed by signal: Interrupt: 2. ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn [19], line 4\u001B[0m\n\u001B[1;32m      3\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(trainloader, \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1348\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent_workers:\n\u001B[0;32m-> 1348\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shutdown_workers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1349\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1474\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1470\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers:\n\u001B[1;32m   1471\u001B[0m     \u001B[38;5;66;03m# We should be able to join here, but in case anything went\u001B[39;00m\n\u001B[1;32m   1472\u001B[0m     \u001B[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001B[39;00m\n\u001B[1;32m   1473\u001B[0m     \u001B[38;5;66;03m# they are killed in the `finally` block.\u001B[39;00m\n\u001B[0;32m-> 1474\u001B[0m     \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMP_STATUS_CHECK_INTERVAL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1475\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/process.py:149\u001B[0m, in \u001B[0;36mBaseProcess.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a started process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 149\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_popen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/popen_fork.py:44\u001B[0m, in \u001B[0;36mPopen.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconnection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m wait\n\u001B[0;32m---> 44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentinel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1997\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   1996\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1997\u001B[0m         stb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInteractiveTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1998\u001B[0m \u001B[43m            \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_offset\u001B[49m\n\u001B[1;32m   1999\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:1112\u001B[0m, in \u001B[0;36mAutoFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1111\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtb \u001B[38;5;241m=\u001B[39m tb\n\u001B[0;32m-> 1112\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFormattedTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:1006\u001B[0m, in \u001B[0;36mFormattedTB.structured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1004\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose_modes:\n\u001B[1;32m   1005\u001B[0m     \u001B[38;5;66;03m# Verbose modes need a full traceback\u001B[39;00m\n\u001B[0;32m-> 1006\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVerboseTB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstructured_traceback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1007\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\n\u001B[1;32m   1008\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1009\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMinimal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:859\u001B[0m, in \u001B[0;36mVerboseTB.structured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 859\u001B[0m formatted_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_as_a_whole\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m colors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mColors  \u001B[38;5;66;03m# just a shorthand + quicker name lookup\u001B[39;00m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:793\u001B[0m, in \u001B[0;36mVerboseTB.format_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m    791\u001B[0m head \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_header(etype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlong_header)\n\u001B[1;32m    792\u001B[0m records \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 793\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_records\u001B[49m\u001B[43m(\u001B[49m\u001B[43metb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_lines_of_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_offset\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m etb \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    794\u001B[0m )\n\u001B[1;32m    796\u001B[0m frames \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py:840\u001B[0m, in \u001B[0;36mVerboseTB.get_records\u001B[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m    839\u001B[0m     style \u001B[38;5;241m=\u001B[39m stack_data\u001B[38;5;241m.\u001B[39mstyle_with_executing_node(style, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbg:ansiyellow\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 840\u001B[0m     formatter \u001B[38;5;241m=\u001B[39m \u001B[43mTerminal256Formatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstyle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstyle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/pygments/formatters/terminal256.py:147\u001B[0m, in \u001B[0;36mTerminal256Formatter.__init__\u001B[0;34m(self, **options)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_color_table()  \u001B[38;5;66;03m# build an RGB-to-256 color conversion table\u001B[39;00m\n\u001B[0;32m--> 147\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup_styles\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# convert selected style's colors to term. colors\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinenos \u001B[38;5;241m=\u001B[39m options\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinenos\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/pygments/formatters/terminal256.py:231\u001B[0m, in \u001B[0;36mTerminal256Formatter._setup_styles\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m ndef[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolor\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m--> 231\u001B[0m     escape\u001B[38;5;241m.\u001B[39mfg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_color_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mndef\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcolor\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ndef[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbgansicolor\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/pygments/formatters/terminal256.py:220\u001B[0m, in \u001B[0;36mTerminal256Formatter._color_index\u001B[0;34m(self, color)\u001B[0m\n\u001B[1;32m    219\u001B[0m b \u001B[38;5;241m=\u001B[39m rgb \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xff\u001B[39m\n\u001B[0;32m--> 220\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_closest_color\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_match[color] \u001B[38;5;241m=\u001B[39m index\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/pygments/formatters/terminal256.py:198\u001B[0m, in \u001B[0;36mTerminal256Formatter._closest_color\u001B[0;34m(self, r, g, b)\u001B[0m\n\u001B[1;32m    197\u001B[0m bd \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m-\u001B[39m values[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m--> 198\u001B[0m d \u001B[38;5;241m=\u001B[39m rd\u001B[38;5;241m*\u001B[39mrd \u001B[38;5;241m+\u001B[39m \u001B[43mgd\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgd\u001B[49m \u001B[38;5;241m+\u001B[39m bd\u001B[38;5;241m*\u001B[39mbd\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m d \u001B[38;5;241m<\u001B[39m distance:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2018\u001B[0m, in \u001B[0;36mInteractiveShell.showtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2015\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_showtraceback(etype, value, stb)\n\u001B[1;32m   2017\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m-> 2018\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mstderr)\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:1954\u001B[0m, in \u001B[0;36mInteractiveShell.get_exception_only\u001B[0;34m(self, exc_tuple)\u001B[0m\n\u001B[1;32m   1949\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1950\u001B[0m \u001B[38;5;124;03mReturn as a string (ending with a newline) the exception that\u001B[39;00m\n\u001B[1;32m   1951\u001B[0m \u001B[38;5;124;03mjust occurred, without any traceback.\u001B[39;00m\n\u001B[1;32m   1952\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1953\u001B[0m etype, value, tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_exc_info(exc_tuple)\n\u001B[0;32m-> 1954\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[43mtraceback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_exception_only\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1955\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(msg)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:140\u001B[0m, in \u001B[0;36mformat_exception_only\u001B[0;34m(etype, value)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_exception_only\u001B[39m(etype, value):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;124;03m\"\"\"Format the exception part of a traceback.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    The arguments are the exception type and value such as given by\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m \n\u001B[1;32m    139\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[43mTracebackException\u001B[49m\u001B[43m(\u001B[49m\u001B[43metype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mformat_exception_only())\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:523\u001B[0m, in \u001B[0;36mTracebackException.__init__\u001B[0;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, _seen)\u001B[0m\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmsg \u001B[38;5;241m=\u001B[39m exc_value\u001B[38;5;241m.\u001B[39mmsg\n\u001B[1;32m    522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lookup_lines:\n\u001B[0;32m--> 523\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:535\u001B[0m, in \u001B[0;36mTracebackException._load_lines\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    533\u001B[0m     frame\u001B[38;5;241m.\u001B[39mline\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__context__:\n\u001B[0;32m--> 535\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__context__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cause__:\n\u001B[1;32m    537\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cause__\u001B[38;5;241m.\u001B[39m_load_lines()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:533\u001B[0m, in \u001B[0;36mTracebackException._load_lines\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;124;03m\"\"\"Private API. force all lines in the stack to be loaded.\"\"\"\u001B[39;00m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m frame \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack:\n\u001B[0;32m--> 533\u001B[0m     \u001B[43mframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mline\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__context__:\n\u001B[1;32m    535\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__context__\u001B[38;5;241m.\u001B[39m_load_lines()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/traceback.py:288\u001B[0m, in \u001B[0;36mFrameSummary.line\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mline\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line \u001B[38;5;241m=\u001B[39m \u001B[43mlinecache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlineno\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_line\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/linecache.py:16\u001B[0m, in \u001B[0;36mgetline\u001B[0;34m(filename, lineno, module_globals)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetline\u001B[39m(filename, lineno, module_globals\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 16\u001B[0m     lines \u001B[38;5;241m=\u001B[39m \u001B[43mgetlines\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_globals\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m lineno \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(lines):\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m lines[lineno\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/linecache.py:54\u001B[0m, in \u001B[0;36mgetlines\u001B[0;34m(filename, module_globals)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# somebody imported something on another thread.\u001B[39;00m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m mods:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(mod, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__file__\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m filename:\n\u001B[1;32m     56\u001B[0m         module_globals \u001B[38;5;241m=\u001B[39m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\n",
      "File \u001B[0;32m~/elastic_notebook2/elastic-notebook/venv/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m callable(previous_handler)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 68720) is killed by signal: Interrupt: 2. "
     ]
    }
   ],
   "source": [
    "%%RecordEvent\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0734c843",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7ddd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bdc49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107f1a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fa0a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de2846",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a7586",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ad5aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%RecordEvent\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46931f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%Checkpoint checkpoints/pytorch.pickle\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}